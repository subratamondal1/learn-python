{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a17f1f8-2431-4145-a23b-0b13e6024788",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Notations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2194f4-0f8c-497f-8fbb-22acaf8a2dd8",
   "metadata": {},
   "source": [
    "## Numerical Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb5e16-fd32-4cac-93fa-2cec20034a88",
   "metadata": {},
   "source": [
    "<img src=\"0.1 numerical_objects.png\" alt=\"Numerical Objects\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71048e7b-9595-472d-8089-b54566edc3a2",
   "metadata": {},
   "source": [
    "## Set Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383df95-1568-4c64-9f14-b35b49f6f1ea",
   "metadata": {},
   "source": [
    "<img src=\"0.2 set_theory.png\" alt=\"Set Theory\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c2ad7b-aa96-492f-9599-c7abd662fcca",
   "metadata": {},
   "source": [
    "## Functions and Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9854d8ab-6a41-485a-b34b-c5f38e7c408c",
   "metadata": {},
   "source": [
    "<img src=\"0.3 functions_and_operators.png\" alt=\"Functions and Operators\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1218b4-beb6-4615-b439-7f4967f34b07",
   "metadata": {},
   "source": [
    "## Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae180c7-e98e-47b7-9549-5c9dda9bfce9",
   "metadata": {},
   "source": [
    "<img src=\"0.4 calculus.png\" alt=\"Calculus\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd150de4-479b-4dc2-b865-1518893a858f",
   "metadata": {},
   "source": [
    "## Probability and Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5181c36a-8484-4ca5-9e55-22e7362a47cb",
   "metadata": {},
   "source": [
    "<img src=\"0.5 probability_and_information_theory.png\" alt=\"Probability and Information Theory\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37183006-8f37-4eb5-b31c-c3b4bd114792",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250182d3-f196-41e8-a2dd-495bb02b8957",
   "metadata": {},
   "source": [
    "<center><strong>Machine learning is the study of algorithms that can learn from experience</strong></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eaa913-5d97-4d41-9e00-ec4005270395",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4705108-cb27-4385-b2ee-c3da802b41af",
   "metadata": {},
   "source": [
    "Traditional computer programs operate on **rigid**, **predefined rules**. For example, an e-commerce platform might use a set of explicit instructions to manage user interactions, database operations, and business logic. While this approach works well for many applications, it falls short when dealing with complex, dynamic, or poorly understood problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252803a-9bff-4ed9-9bed-ba88ea792027",
   "metadata": {},
   "source": [
    "### Limitations of Rule-Based Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18dd6c1-1949-44b6-a7cd-09c29013a44c",
   "metadata": {},
   "source": [
    "Consider these challenging tasks:\n",
    "- Predicting tomorrow's weather\n",
    "- Answering free-form text questions\n",
    "- Identifying people in images\n",
    "- Recommending products users might enjoy\n",
    "\n",
    "These problems are difficult to solve with traditional programming methods due to:\n",
    "1. Changing patterns over time\n",
    "2. Complex relationships between inputs and outputs\n",
    "3. Processes that lie beyond our conscious understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed28108d-43f1-4ca4-a535-1d6b8dd22c74",
   "metadata": {},
   "source": [
    "### The Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a37432-0035-468b-9a2f-45194c0bb896",
   "metadata": {},
   "source": [
    "**Machine learning algorithms learn from experience**, typically in the form of data or environmental interactions. As they accumulate experience, their performance improves. This adaptability makes machine learning particularly suited for tasks where:\n",
    "\n",
    "1. Patterns change over time\n",
    "2. Relationships are too complex for manual coding\n",
    "3. The precise steps to perform the task are unknown\n",
    "\n",
    "Deep learning, a powerful subset of machine learning techniques, is driving innovations in various fields, including computer vision, natural language processing, healthcare, and genomics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d3a7d-6f6b-4ccf-a29f-e5fec836a024",
   "metadata": {},
   "source": [
    "## A Motivating Example: Voice Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc371e5e-9292-471c-912a-1fe009796078",
   "metadata": {},
   "source": [
    "Modern smartphones use multiple machine learning models in everyday interactions. Consider the process of using voice commands to get directions:\n",
    "\n",
    "1. Wake word recognition (\"Hey Siri\")\n",
    "2. Speech-to-text conversion\n",
    "3. Natural language processing\n",
    "4. Route planning and travel time prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572e43a-cbe8-4f00-b0a4-4ad69cb6ff68",
   "metadata": {},
   "source": [
    "### The Challenge of Programming Voice Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908813fd-ea8d-4de6-9f2e-9540d5c94866",
   "metadata": {},
   "source": [
    "Coding a wake word recognizer from scratch is extremely difficult:\n",
    "\n",
    "- Audio input: ~44,000 samples per second\n",
    "- Complex mapping from raw audio to yes/no predictions\n",
    "- No clear rules for recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4d4d11-67ea-44f3-9812-5208193fd4be",
   "metadata": {},
   "source": [
    "### The Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb5012-21f4-4fd3-a13f-f295faacda83",
   "metadata": {},
   "source": [
    "Instead of explicit programming, we:\n",
    "\n",
    "1. Collect a large dataset of audio snippets and labels\n",
    "2. Define a flexible program with **adjustable parameters**\n",
    "3. Use a learning algorithm to find optimal parameter values\n",
    "\n",
    "Key concepts:\n",
    "- **Model**: A program with fixed parameters\n",
    "- **Model family**: Set of all possible programs created by adjusting parameters\n",
    "- **Learning algorithm**: Process that uses data to adjust the parameters for learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528cdfd-15cf-432e-8d59-122d56ba7128",
   "metadata": {},
   "source": [
    "### The Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef92c6-2d83-43c4-b93a-8c99277a8344",
   "metadata": {},
   "source": [
    "1. Start with a **randomly initialized model**\n",
    "2. Use **labeled data** (audio snippets and corresponding labels)\n",
    "3. **Adjust parameters** to improve performance on the data\n",
    "4. Repeat steps 2-3 until satisfactory performance is achieved\n",
    "\n",
    "This approach, \"programming with data,\" allows us to create complex systems like wake-word recognizers, image classifiers, and more without explicitly coding the rules. **Deep learning** is the key to solve these kind of problems.\n",
    "\n",
    "<img src=\"1.1.2 training process.png\" alt=\"Training Process\" width=\"800\"/>\n",
    "\n",
    "To summarize, rather than code up a wake-word recognizer, we code up a program that can **learn** to recognize wake words from large dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc3181e-4726-4e0f-b6ff-f835aa613ce3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Key Components\n",
    "1. **Data:** to learn from.\n",
    "2. **Model:** to transform the data.\n",
    "3. **Objective/Loss Function:** to quantify how well the model is doing.\n",
    "4. **Optimization Algorithm:** to optimize the objective/loss function by adjusting the model’s parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fa825c-aec1-49f6-8aaa-3952dc84910f",
   "metadata": {},
   "source": [
    "### 1.Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a91e6b-f947-4fe0-944d-e62f6534a31b",
   "metadata": {},
   "source": [
    "The foundation of any machine learning task is data, which consists of examples with features (inputs) and labels (targets). The data must be accurately represented numerically. Fixed-length vectors are convenient but not always possible, especially with varying-length data like text. Large, high-quality datasets are crucial for training effective models, as poor data quality can lead to biased or inaccurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bee8df-15ed-435d-be88-08ee8ae8b1bd",
   "metadata": {},
   "source": [
    "### 2.Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61631036-454a-4291-b99e-e9e3179adf4a",
   "metadata": {},
   "source": [
    "Models transform data into predictions. They can range from simple statistical models to complex deep learning architectures. Deep learning models are characterized by multiple layers of transformations, allowing them to handle complex tasks that simpler models cannot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed18e3-75fa-4ff6-8539-db215eaabdb3",
   "metadata": {},
   "source": [
    "### 3. Objective/Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8068a3-6247-40af-bfe5-98432c3299a4",
   "metadata": {},
   "source": [
    "These functions measure the performance of a model. Typically, lower values indicate better performance. Common objective functions include squared error for regression and error rate for classification. In practice, surrogate objectives might be used for optimization due to the complexity of directly optimizing some functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2caef-a587-49cc-afe1-79cdb343dc07",
   "metadata": {},
   "source": [
    "### 4. Optimization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b11f82e-e9c2-48b3-a79a-63b6a626002d",
   "metadata": {},
   "source": [
    "Algorithms like gradient descent are used to adjust model parameters to minimize the loss function. This involves iteratively updating parameters in the direction that reduces the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43933d0-ced9-45fa-8242-2312214febe7",
   "metadata": {},
   "source": [
    "## Kinds of Machine Learning Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97838790-42cd-41e4-9e74-1dfbc0fffe4c",
   "metadata": {},
   "source": [
    "### Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a800c56a-9e8a-42bb-aeb1-92f914fd672e",
   "metadata": {},
   "source": [
    "Algorithm Trained on Labeled Dataset i.e input-label features also known as example.\n",
    "\n",
    "Supervised learning can be divided into two main types:\n",
    "- **Classification**: Predicts `discrete categories`, such as determining if an email is spam or not.\n",
    "- **Regression**: Predicts `continuous values`, like estimating house prices based on features.\n",
    "\n",
    "- **Applications**: Supervised learning is used in various applications, including image recognition, fraud detection, and medical diagnosis.\n",
    "\n",
    "- **Optimization**: Models are optimized using loss functions, such as **cross-entropy** for classification and **squared error** for regression, to minimize prediction errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7553071-90aa-4fb9-8763-fadb8d075c31",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8269b5d-dd82-489f-acc6-341c73eccd05",
   "metadata": {},
   "source": [
    "Regression is focused on predicting **continuous numerical value target** from input features. It is commonly used to answer **\"how much?\"** or **\"how many?\"** questions.\n",
    "\n",
    "- **Feature Vectors**: Each example (input-label) is represented by a **fixed-length vector** of features.\n",
    "\n",
    "**Real-World Applications**: \n",
    "  - Predicting movie ratings based on user preferences.\n",
    "  - Estimating the duration of a surgery.\n",
    "  - Forecasting rainfall amounts.\n",
    "\n",
    "**Modeling and Loss Function**: Regression models aim to minimize the difference between predicted and actual values, often using the **squared error loss** function. This approach assumes data may be affected by Gaussian noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7267ba-aa67-4c5c-91f1-a1ca3cc0c3f4",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142798d-af08-4b63-b67d-8ba3138432ab",
   "metadata": {},
   "source": [
    "Classification is focused on predicting the **category or class of an input** from a discrete set of options.\n",
    "\n",
    "- **Binary Classification**: Involves two classes, such as determining whether an email is spam or not.\n",
    "\n",
    "- **Multiclass Classification**: Involves more than two classes, such as classifying handwritten digits (0-9). Models assign **probabilities** to each class, allowing for uncertainty estimation.\n",
    "\n",
    "- **Hierarchical Classification**: Addresses structured classes where errors vary in severity. For example, confusing similar dog breeds is less severe than confusing a dog with a dinosaur.\n",
    "\n",
    "**Model Output and Optimization:**\n",
    "\n",
    "- **Probabilistic Output**: Models often output probabilities for each class, which helps in decision-making by conveying uncertainty. For instance, a model might predict a 90% probability that an image is a cat.\n",
    "\n",
    "- **Loss Function**: **Cross-entropy** is commonly used to measure the difference between predicted and true class probabilities.\n",
    "\n",
    "\n",
    "**Risk Assessment**: Beyond probabilities, decision-making involves weighing potential risks and benefits. For example, even with an 80% probability that a mushroom is safe, the risk of it being poisonous may deter consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2006949-455a-41ec-9e98-e40d5a604de2",
   "metadata": {},
   "source": [
    "### Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc05bb77-d2ca-4e46-88fc-65c41aa62b20",
   "metadata": {},
   "source": [
    "In the context of classification problems, traditional binary or multiclass classification might not always be suitable, especially when dealing with scenarios **where multiple labels can be applied simultaneously**. A classic example is identifying animals in an image like the \"Town Musicians of Bremen,\" which features multiple animals together. In such cases, multi-label classification is more appropriate, allowing the model to identify all present categories, such as a cat, dog, donkey, and rooster, rather than forcing a single category choice.\n",
    "\n",
    "This concept extends to **auto-tagging** problems, such as tagging posts on a technical blog with multiple relevant categories like \"machine learning,\" \"technology,\" and \"cloud computing.\" These tags often exhibit correlation, as certain topics frequently appear together.\n",
    "\n",
    "In more complex scenarios, such as tagging medical articles in **PubMed**, a vast set of possible tags exists, drawn from the **Medical Subject Headings (MeSH)** ontology, which includes around 28,000 tags. Accurate tagging is crucial for facilitating comprehensive literature reviews. Given the time-consuming nature of manual tagging, machine learning can assist by providing provisional tags, helping bridge the gap until a manual review is completed. **Competitions** like those hosted by **BioASQ** aim to improve machine learning techniques for such tasks.\n",
    "\n",
    "<img src=\"1.3.3 tagging.png\" alt=\"Tagging\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8b6a34-cd54-42c8-9259-057e29935052",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f53978-39ef-4e8e-bcf3-c108d56ac2f0",
   "metadata": {},
   "source": [
    "In **information retrieval**, particularly in web search, the focus is on **ranking items** to determine which results should be most prominently displayed to a user. The objective is not just to identify relevant pages, but to prioritize them effectively. Initially, systems like **Google's PageRank** assigned scores to pages based on their authority, independent of the specific query. This involved a simple relevance filter to identify relevant candidates, followed by using PageRank to prioritize them.\n",
    "\n",
    "Today, search engines have evolved to use machine learning and **behavioral models** to generate query-dependent relevance scores, allowing for more personalized and accurate search results. This area of study is so significant that it has spawned entire academic conferences dedicated to exploring and advancing these techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a58ad1-0c2d-4db0-904f-c113d01f2919",
   "metadata": {},
   "source": [
    "### Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f509a-55b2-4bfe-b212-e0aa5c48d7f4",
   "metadata": {},
   "source": [
    "Recommender systems are closely **related to search** and **ranking**, with the key distinction being their focus on personalizing content for individual users. Unlike search engines, which aim to rank relevant items for general queries, recommender systems tailor their suggestions based on user-specific preferences. For example, a science fiction fan and a Peter Sellers comedy enthusiast would receive different movie recommendations.\n",
    "\n",
    "These systems **rely on** both **explicit feedback**, like product ratings and reviews, and **implicit feedback**, such as skipped songs in a playlist, to estimate user preferences. The simplest models predict scores like expected ratings or purchase probabilities, which are then used to recommend items with the highest scores to users. Advanced systems incorporate detailed user behavior and item characteristics to refine these predictions.\n",
    "\n",
    "Despite their economic value, recommender systems face challenges due to their reliance on censored feedback, where users tend to rate only items they feel strongly about, leading to skewed data. Additionally, feedback loops can occur, where items recommended more frequently are perceived as better due to increased purchases, reinforcing their prominence in recommendations. Addressing issues like feedback loops and data censoring remains an important area of ongoing research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376a22e-f69d-45bb-a77b-1d6c94e57b7d",
   "metadata": {},
   "source": [
    "### Sequence Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b254c19-a81b-43e6-bd14-9f487c9c2e53",
   "metadata": {},
   "source": [
    "Sequence learning addresses problems where **inputs** and **outputs** are **not fixed in number**, but rather consist of sequences that can vary in length. Unlike traditional models that handle independent observations, sequence learning models consider the context provided by previous and succeeding elements in a sequence, making them suitable for tasks like video analysis, language processing, and medical monitoring.\n",
    "\n",
    "In sequence learning, models are designed to handle sequences of inputs and/or outputs. A key example is sequence-to-sequence learning, where both inputs and outputs are variable-length sequences. This is crucial for tasks such as:\n",
    "\n",
    "- **Machine Translation**: Translating sentences from one language to another, where input and output sequences may differ in length and order.\n",
    "- **Automatic Speech Recognition**: Converting audio recordings into text, where the audio input is much longer than the text output.\n",
    "- **Text to Speech**: The reverse of speech recognition, where text is converted into audio, resulting in a longer output sequence.\n",
    "\n",
    "Other sequence learning tasks include **tagging** and **parsing**, where text sequences are annotated with attributes like **parts of speech** or **named entities**, and **dialogue systems**, which require understanding context over long temporal distances.\n",
    "\n",
    "Sequence learning is a vibrant area of research, with challenges such as handling unaligned data, as seen in machine translation, and managing complex dialogue interactions. These tasks require sophisticated models that can capture the nuances of sequential data, making sequence learning one of the most exciting applications of machine learning today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e225627f-25cb-4780-8493-a3d42584b5d4",
   "metadata": {},
   "source": [
    "## Unsupervised and Self-Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66314074-7ebd-4b6c-b8e7-f8bd3db9189f",
   "metadata": {},
   "source": [
    "**Unsupervised** and **self-supervised learning** represent areas of machine learning **where models learn from data without explicit labels** unlike supervised learning, where models are trained with labeled datasets. This approach is akin to working with a vague directive, where the data scientist must creatively determine the questions to ask and the insights to derive.\n",
    "\n",
    "**Unsupervised Learning** focuses on tasks such as:\n",
    "\n",
    "- **Clustering**: Grouping data into categories, like sorting photos into landscapes, animals, and people, or categorizing users based on browsing behavior.\n",
    "- **Subspace Estimation / Dimensionality Reduction**: Identifying a small set of parameters that capture essential data characteristics, such as using principal component analysis to reduce dimensionality.\n",
    "- **Representation in Euclidean Space**: Mapping complex objects and their relationships into a space where symbolic properties are well-matched.\n",
    "- **Causality and Probabilistic Models**: Understanding the root causes and relationships within data, such as analyzing demographic factors affecting house prices.\n",
    "\n",
    "A significant advancement in unsupervised learning is **deep generative models**, which **estimate data density** and **generate new data** samples. Notable models include **variational autoencoders, generative adversarial networks, normalizing flows,** and **diffusion models**.\n",
    "\n",
    "**Self-Supervised Learning** leverages unlabeled data to create supervisory signals. In text, models can **predict masked words using context**, while in images, models might learn by predicting the relative position of image parts or identifying perturbed versions of the same image. These techniques often produce robust representations that can be fine-tuned for specific tasks, enhancing their applicability in various domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6e11d-a327-461a-9041-fd3550d58e43",
   "metadata": {},
   "source": [
    "## Interacting with Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2c9ab-9871-4460-bc64-cc99035bde2a",
   "metadata": {},
   "source": [
    "Interacting with an environment introduces a dynamic aspect to machine learning that goes beyond the static nature of offline learning. In traditional supervised and unsupervised learning, models are trained on pre-collected datasets without further interaction with the environment. This approach, known as **offline learning**, allows for isolated pattern recognition but limits the capability to develop intelligent agents that can act and adapt in real-world scenarios.\n",
    "\n",
    "To create truly intelligent agents, we need to consider how actions impact the environment and future observations. This involves addressing several key questions:\n",
    "\n",
    "- Does the environment remember what we did previously?\n",
    "- Does the environment want to help us, e.g., a user reading text into a speech recognizer?\n",
    "- Does the environment want to beat us, e.g., spammers adapting their emails to evade spam filters?\n",
    "- Does the environment have shifting dynamics? For example, would future data always resemble the past or would the patterns change over time, either naturally or in response to our automated tools?\n",
    "\n",
    "These considerations lead to the concept of **distribution shift**, where the data encountered during deployment differs from the training data. This is akin to facing different exam questions than those practiced in homework.\n",
    "\n",
    "**Reinforcement learning** provides a framework for addressing these challenges by allowing an agent to learn through interaction with the environment. The **agent makes decisions, receives feedback,** and **adjusts its actions** to maximize long-term rewards, making it well-suited for scenarios where actions directly impact future states and observations. This approach is essential for developing adaptive, intelligent systems capable of operating effectively in dynamic and complex environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d588ca2-f22a-455d-bf2d-83677205bc29",
   "metadata": {},
   "source": [
    "## Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd9821-2f99-4b29-acfa-e87abfefb0c5",
   "metadata": {},
   "source": [
    "**Reinforcement learning (RL)** is a machine learning paradigm focused on **developing agents** that interact with environments to make decisions and take actions. It is particularly useful in applications such as robotics, dialogue systems, and AI for video games. **Deep reinforcement learning**, which combines deep learning with RL, has gained prominence with achievements like the **deep Q-network** surpassing humans in Atari games and AlphaGo defeating the world champion in Go.\n",
    "\n",
    "In RL, an agent interacts with an environment over time, receiving observations and selecting actions that influence the environment. The agent receives rewards based on its actions, and its behavior is guided by a policy—a function mapping observations to actions. The primary goal is to develop policies that maximize long-term rewards.\n",
    "\n",
    "RL is versatile and can be applied to problems beyond the scope of supervised learning. Unlike supervised learning, where inputs come with correct labels, RL does not assume optimal actions for each observation. Instead, agents receive rewards, which may not directly indicate which actions led to success, presenting the credit assignment problem. For example, in chess, the reward comes only at the game's end, requiring the agent to determine which moves contributed to winning or losing.\n",
    "\n",
    "RL also addresses partial observability, where current observations might not fully reveal the agent's state. For instance, a cleaning robot trapped in a closet must infer its location based on previous observations.\n",
    "\n",
    "A key challenge in RL is balancing exploration and exploitation. An agent must decide whether to exploit known strategies for immediate rewards or explore new strategies that might yield better long-term outcomes.\n",
    "\n",
    "The RL framework encompasses various problem settings:\n",
    "\n",
    "- **Markov Decision Processes (MDPs)**: When the environment is fully observable.\n",
    "- **Contextual Bandit Problems**: When the state does not depend on previous actions.\n",
    "- **Multi-Armed Bandit Problems**: When there is no state, just a set of actions with unknown rewards.\n",
    "\n",
    "These specialized cases help researchers tackle RL problems with varying levels of complexity, making RL a versatile and widely applicable approach in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bc71bb-3feb-4614-bea2-42180c33fbba",
   "metadata": {},
   "source": [
    "<img src=\"1.3.7 reinforcement learning.png\" alt=\"Reinforcement Learning\" width=800/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b3769b-f8b5-4542-bd05-ec0448076177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
