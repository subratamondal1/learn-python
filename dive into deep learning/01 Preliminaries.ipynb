{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fabac6e-a6ff-4c44-b0fa-4c7ae70e4151",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9975ea-becb-4f38-9936-129983d62e71",
   "metadata": {},
   "source": [
    "To prepare for your dive into deep learning, you will need a few survival skills: \n",
    "- (i) techniques for **storing** and **manipulating** data;\n",
    "- (ii) libraries for **ingesting** and **preprocessing** data from a variety of sources;\n",
    "- (iii) knowledge of the basic linear algebraic operations that we apply to high-dimensional data elements;\n",
    "- (iv) just enough calculus to determine which direction to adjust each parameter in order to decrease the loss function;\n",
    "- (v) the ability to automatically compute derivatives so that you can forget much of the calculus you just learned;\n",
    "- (vi) some basic fluency in probability, our primary language for reasoning under uncertainty;\n",
    "- (vii) some aptitude for finding answers in the official documentation when you get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761897ee-99a4-4f24-90d5-f62647d850b9",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17bdcaf-e132-4c0d-9c8f-86b88538cb25",
   "metadata": {},
   "source": [
    "In order to get anything done, we need some **way to store** and **manipulate data**. Generally, there are two important things we need to do with data: \n",
    "- (i) acquire them;\n",
    "- (ii) process them once they are inside the computer.\n",
    "\n",
    "There is no point in acquiring data without some way to store it, so to start, let’s get our hands dirty with **n-dimensional arrays**, which we also call **tensors**. If you already know the NumPy scientific computing package, this will be a breeze. For all modern deep learning frameworks, the tensor class (ndarray in MXNet, Tensor in PyTorch and TensorFlow) resembles NumPy’s ndarray, with a few killer features added. \n",
    "- First, the **tensor class supports automatic differentiation**.\n",
    "- Second, it **leverages GPUs to accelerate numerical computation**, whereas NumPy only runs on CPUs.\n",
    "\n",
    "These properties make neural networks both easy to code and fast to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c854dac2-e57c-4ca6-847b-d34309eebee4",
   "metadata": {},
   "source": [
    "To start, we import the **PyTorch** library. Note that the package name is **torch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07d8d0f-60ba-43b6-b993-b1aff832db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0050f76d-2e6c-45bd-bfd0-01ae454c765c",
   "metadata": {},
   "source": [
    "A tensor represents a (possibly multidimensional) array of numerical values. In the one-dimensional case, i.e., when only one axis is needed for the data, a tensor is called a **vector**. With two axes, a tensor is called a **matrix**. With `k>2` axes, we drop the specialized names and just refer to the object as a $k^{th}$**-order tensor**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714e866c-7d74-4844-8248-b713ebcdecae",
   "metadata": {},
   "source": [
    "PyTorch provides a variety of functions for creating new tensors prepopulated with values. For example, by invoking arange(n), we can create a vector of evenly spaced values, starting at 0 (included) and ending at n (not included). By default, the interval size is 1. Unless otherwise specified, new tensors are stored in main memory and designated for CPU-based computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec5eafc-2df9-4899-82bd-53e1e52efe9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(12, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a2dd3-dde4-401c-bae9-5d169790a320",
   "metadata": {},
   "source": [
    "Each of these values is called an **element** of the tensor. The tensor x contains 12 elements. We can inspect the total number of elements in a tensor via its **`numel`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad86fee-e4d5-46cc-9c1b-febf60d2da03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9315d86e-39dc-440b-963c-fb0bc440a79b",
   "metadata": {},
   "source": [
    "We can access a tensor’s shape (the length along each axis) by inspecting its **shape** attribute. Because we are dealing with a vector here, the shape contains just a single element and is identical to the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98e4e7d-98fc-4c5a-b0eb-71e01b3a9858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb37d14-69ff-4144-bb6d-f6748798f51c",
   "metadata": {},
   "source": [
    "We can change the **shape** of a tensor **without altering its size or values**, by invoking reshape. For example, we can transform our vector x whose shape is (12,) to a matrix X with shape (3, 4). This new tensor retains all elements but reconfigures them into a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a6c87d9-2228-414a-888e-4539f894fec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = x.reshape(3, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ead00-5166-4783-8997-07381c0933ea",
   "metadata": {},
   "source": [
    "Note that specifying every shape component to reshape is redundant. Because we already know our tensor’s size, we can work out one component of the shape given the rest. For example, given a tensor of size `n` and target shape `(h,w)`, we know that `w=n/h`. To automatically infer one component of the **shape**, we can place a **-1** for the shape component that should be **inferred automatically**. In our case, instead of calling x.reshape(3, 4), we could have equivalently called **x.reshape(-1, 4)** or **x.reshape(3, -1)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb9e2eb7-9ae2-48b5-aebe-cf3a35db21bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "X = x.reshape(3, -1)\n",
    "print(X.shape)\n",
    "\n",
    "X = x.reshape(-1, 4)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b18af-c723-4319-b6ed-d482ec2a4ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
